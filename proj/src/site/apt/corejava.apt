 -----
 The APT format: 
 -----
 The Maven Team:
 -----
 -----

<<Core Java>>

 <<An object has three characteristics:>>
 
 [[1]] <<state:>> represents data (value) of an object.
	
 [[2]] <<behavior:>> represents the behavior (functionality) of an object such as deposit, withdraw etc.
	
 [[3]] <<identity:>> Object identity is typically implemented via a unique ID. 
 
 		The value of the ID is not visible to the external user. 
 		But, it is used internally by the JVM to identify each object uniquely

[]
 
 <The new keyword is used to allocate memory at run time. All objects get memory in Heap memory area.>

 <<Initializing object>>
 
 [[1]] By <<reference:>> s1.rollNo=10; s1.name="ravi";
	
 [[2]] By <<method:>> s1.insertRecord(10,"ravi");
	
 [[3]] By <<constructor:>> new Student(10,"ravi");
 
[]

+-------------------------------+	
 Student
 {
	int rollNo;
	String name;
	insertRecord(int rollNo,String name){}
	Student(){}
	Student(int rollNo,String name){}
 }
+-------------------------------+

 <<What are the different ways to create an object ?>>

 [[1]] By new keyword
	
 [[2]] By clone() method
	
 [[3]] By deserialization
	
 [[4]] By newInstance() method
 
 	   Class.forName("ClassName").newInstance(); <it internally uses new key word.>
	
 [[5]] By factory method etc <it internally uses new key word.>
 
 <Ex: ObjectCreationWays.java>
 
 []
	
 <Actually, 3 ways to create objects.(><<new keyword>>, <<clone()>> and <<deserialization>><).>

 <<Usage of >><static><< keyword:>>

 [[1]]variables
	
 [[2]]methods
	
 [[3]]block
	
 [[4]]nested class
 
 []
	
 <static method can not access non-static data members and methods directly.>
 
 <static method can not use this and super keywords.>

 <<Usage of >><this><< keyword:>> refers to current class object.
 
+-------------------------------+
  this.instanceVarible      ----- refers to current class variables
  this.instanceMethod()     ----- refers to current class instance method
  method(this)              ----- can be passed as method argument
  Constructor(this)         ----- can be passed as constructor argument
  this()                    ----- constructor-default
  return this;              ----- returns current class obj.
+-------------------------------+

 <<Inheritance:>>  One object/class acquires all the properties and behavior of parent object/class. code reusability and runtime polymorphism.
  
 [[1]] <<IS-A>> relationship or parent-child relation: <a class extends other class>
	
 [[2]] Aggregation or <<Has-A>> relation:If <a class has an entity reference> is known as Aggregation.
	
 [[3]] <<Consist-A>> relation:If <a method/block has an entity reference>
 
 []
	
 <<Types of Inheritance:>>
	 
 [[1]] Single
	 
 [[2]] Multilevel
	 
 [[3]] Hierarchical
	  	
 [[4]] Multiple(with interfaces)
	 
 [[5]] Hybrid(with interface)
 
 []
		
 <<Method overloading:>> If a class has multiple methods having same name but different in parameters, it is known as method overloading.
 		Method Overloading is not possible by changing the return type of the method only because of ambiguity.
	
 <Compile Time Error is better than Run Time Error.> So, java compiler renders compiler time error if you declare the same method having same parameters inside a class.

 <<Method overriding:>> If subclass (child class) has the same method as declared in the parent class, it is known as method overriding. 
 		Method overriding is used to provide <specific implementation> of a method that is already provided by its super class & used for runtime polymorphism.

 <<super keyword:>> <super> keyword is a reference variable which is used to refer <immediate parent class object>. 
 		Whenever we create the instance of subclass, an instance of parent class is created implicitly which is referred by super reference variable.

+-------------------------------+		
 super() : default constructor
 super.instanceMethod()
 super.instanceVariable;
+-------------------------------+
	
 <super() is added in each class constructor automatically by compiler if there is no super()>
 <if we want to call immediate parent call constructor it should be 1st statement inside current class constructor.>
 
 <<Usage of >><final><< keyword:>> <final> keyword can be used at the following levels. 
 
+-------------------------------+	
 variable ------ constants, can not be modified once initialized or assigned value at 1st time.
 method   ------ can not be overridden in subclass.
 class    ------ can not be inherited.
+-------------------------------+	

 <<Polymorphism >> It is a concept by which we can perform a single action by different ways.		
 
 [[1]] <<Compile time polymorphism:>> Caller of the method is identified at compile time.
	
		Ex:  overloaded static methods
 
 [[2]] <<Runtime polymorphism>> <(Dynamic Method Dispatch):>
		It is a process in which a call to an overridden method is resolved at runtime rather than compile-time.
		In this process, an overridden method is called through the reference variable of a superclass. 
		The determination of the method to be called is based on the object being referred to by the reference variable.
	
		<Method can be overridden not the datamembers, so runtime polymorphism can't be achieved by data members.>		

[]

 <<Static Binding and Dynamic Binding:>>
		Connecting a method call to the method body is known as binding.
		There are two types of binding
	
 [[1]] <<Static binding>> <(Early binding):>
 
		When type of the object is determined at compiled time(by the compiler), it is known as static binding. 
		If there is any <private, final or static method in a class>, there is static binding.
		
 [[2]] <<Dynamic binding>> <(Late binding):>
  
		When type of the object is determined at run time, it is known as late binding. Overridden methods
 
 []
	
 <<instanceof>> <type comparison operator> is used to test whether the object is an instance of the specified type (class or subclass or interface).
 
 <<Downcasting>> When Subclass type refers to the object of Parent class, it is known as downcasting.
		If we perform it directly, compiler gives Compilation error. If you perform it by typecasting, ClassCastException is thrown at runtime. 
		But if we use instanceof operator, downcasting is possible.

 <<Upcasting>> When Parent type refers to the object of child class, it is known as upcasting.


 <<Abstraction>> It is a process of hiding the implementation details and showing only functionality to the user.
 		There are two ways to achieve abstraction.

 [[1]] <<Abstract class (0 to 100%)>>
 		An abstract class can have data member, abstract method, concrete method, constructor and even main() method.

 [[2]] <<Interface (100%)>>
		It is a blueprint of a class. It has static constants and abstract methods.
		It also represents IS-A relationship. Multiple inheritance is not supported in case of class because of ambiguity. 
		But it is supported in case of interface because there is no ambiguity as implementation is provided by the implementation class. 
		
		<<Marker interfacs>>< or ><<Tagged interface>>< :An interface that have no member.>
		They are used to provide some essential information to the JVM so that JVM may perform some useful operation.
		
		<Ex: Serializable, Cloneable, Remote etc.>
		
		If the JVM sees a Class is implementing the Serializable interface it does some special operation on it and writes the state of the object into object stream. 
		This object stream is then available to be read by another JVM. 
		
		If JVM finds that a class is implementing Clonnable interface, it performs some special operation in order to support cloning. 
		The same theory goes for RMI and Remote interface.
 
 		With the introduction of annotation, annotation has become a better choice over maker interface.
		In short a marker interface  is used to indicate something to compiler, JVM or any other tool but Annotation is better way of doing same thing.
 
 		Ref: {{http://mrbool.com/what-is-marker-interface-in-java/28557}}
		
 []
 
 <<Factory method>> A factory method is the method that returns the instance of the class.

 <<Serialization>> is the process of converting the state of an object into byte stream so that the byte stream can be reverted back into a copy of the object.
 
 <<Deserialization>> is the process of converting the serialized form of an object back into a copy of the object.
 
		<Any class which implements <java.io.Serializable interface> or <java.io.Externalizable> can be serialized and deserialized.>
  
  <<Immutable class and custom immutable class>> 
  
  TO-DO.......................
  
  ............................
  
  
 <<Access modifiers :>>
	
	[[1]] private-variable,method,constructor
	
	[[2]] default
	
	[[3]] protected
	
	[[4]] public
	
	[]

+----------------------------+	
	private-> default-> protected-> public
	
	If you are overriding any method, overridden method (i.e. declared in subclass) must not be more restrictive.
+----------------------------+
	
 <<Non-Access modifiers :>>
 
	[[1]] static
	
	[[2]] abstract
	
	[[3]] synchronized
	
	[[4]] native
	
	[[5]] volatile
	
	[[6]] transient ...etc
	
	[]
	


 <<Encapsulation:>> It is a process of wrapping code and data together into a single unit.
		By providing only setter or getter method, you can make the class read-only or write-only. Fully encapsulated class- java bean

 <<Nested Class>>
 
	[[1]] <<static nested class >> <(static nested class):> Static nested classes can access only static members of the outer class.
	
	[[2]] <<inner class >><(non static nested class):> can access all the variables and methods of the outer class. we can not have any static variables inside them.
	
		[[i]] <<Local inner class :>> A class is defined in a method body/block.
		
		[[ii]] <<Anonymous inner class:>> A local inner class without name is known as anonymous inner class.
		
	  
 <<ClassLoader>>

	[[1]] <<Bootstrap class loader:>> Every JVM implements this loader.
		It loads core java API classes from <JAVA_HOME/jre/lib directory>(bootstrap path).
		
		<This is implemented by native languages like C C++.>
								
	[[2]] <<Extension class loader:>> Child of Bootstrap class loader. implemented by java.
		It loads classes form <JAVA_HOME/jre/lib/ext> or any other path specified by <java.ext.dirs> path
		
		JVM implemented extension class loader is <sun.misc.Launcher$ExtClassLoader> class.
								
	[[3]] <<System/Application class loader:>>It is child of extension class loader.
		It loads classes from <application path> or any other from environment variable <java.class.path>.
		
		JVM implemented extension class loader is <sun.misc.Launcher$AppClassLoader> class.
	
 <<Concurrent systems>> Multiple threads communicate each other. 
 
 <<Distributed systems>> Multiple processors communicate each other(different computers).

 <<Mutithreading & Concurrency :>> {{http://tutorials.jenkov.com/java-concurrency/benefits.html}}
 
 <<Concurrent model>>
 
	[[1]] <<Parallel Workers:>> Incoming jobs are assigned to different workers. A delegator distributes the incoming jobs to different workers.
		Each worker completes the full job. 
		The workers work in parallel, running in different threads, and possibly on different CPUs.
		The parallel worker concurrency model is the most commonly used concurrency model in Java.
		
		<Ex: Many of the concurrency utilities in the java.util.concurrent>
						 
+-------------------------------+							 
 + Easy to understand
 + Add workers to increase parallelization.
						 
 - Shared state(in memory or/and database) access is complex
 - The job execution order is nondeterministic. 
+-------------------------------+	
					 
 Additionally, part of the parallelization is lost when threads are waiting for each other when accessing the shared data structures.
 <Many concurrent data structures> are <blocking>, meaning one or a limited set of threads can access them at any given time.
 
 <Modern non-blocking concurrency> algorithms may decrease contention and increase performance, but non-blocking algorithms are hard to implement.
 
 <A persistent data structure> always preserves the previous version of itself when modified. 
 If multiple threads point to the same persistent data structure and <one thread modifies it, the modifying thread gets a reference to the new structure. 
 All other threads keep a reference to the old structure which is still unchanged and thus consistent.>
 
 While persistent data structures are an elegant solution to concurrent modification of shared data structures, <persistent data structures tend not to perform that well.>						 

	[[2]] <<Assembly Line>> or <<Shared nothing>> or <<Reactive or Event Driven System:>> The workers are organized like workers at an assembly line in a factory. 
 Each worker only performs a part of the full job. When that part is finished the worker forwards the job to the next worker.
 
 Systems using the assembly line concurrency model are usually designed to use non-blocking IO.
 <Non-blocking IO means that when a worker starts an IO operation (e.g. reading a file or data from a network connection) the worker does not wait for the IO call to finish.>
 
 <The system's workers react to events occurring in the system, either received from the outside world or emitted by other workers. Examples of events could be an incoming HTTP request, or that a certain file finished loading into memory etc.>
	
+-------------------------------+					    
	+ No shared data
	+ Stateful workers
	+ Job ordering
	  					
	- Hard to identify which part of code is being executed: that the execution of a job is often spread out over multiple workers, and thus over multiple classes in your project. Thus it becomes harder to see exactly what code is being executed for a given job.
+-------------------------------+	
	  					
	[[3]] <<Functional Parallelism:>> The basic idea of functional parallelism is that you implement your program using function calls. 
 Functions can be seen as "agents" or "actors" that send messages to each other, just like in the assembly line concurrency model.
 With Java 7 we got the java.util.concurrent package contains the ForkAndJoinPool which can help you implement something similar to functional parallelism.
 With Java 8 we got parallel streams which can help you parallelize the iteration of large collections. 

 <In order to utilize all the cores in the CPU, a single-threaded system can be scaled out to utilize the whole computer.>

	[[4]] Same-threading: is a concurrency model where a single-threaded systems are scaled out to N single-threaded systems. 
					   The result is N single-threaded systems running in parallel.
					   A same-threaded system is not a pure single-threaded system, because it contains of multiple threads. 
					   But - each of the threads run like a single-threaded system.
					   
	[]
					   
 <<Concurrency:>> Multiple tasks progress at the same time.

 <<Parallelism:>> Each task is broken into subtasks which can be processed in parallel.

 <An application may process one task at at time (sequentially) or work on multiple tasks at the same time (concurrently).>
 <Parallelism on the other hand, is related to how an application handles each individual task. An application may process the task serially from start to end, or split the task up into subtasks which can be completed in parallel.>

 <<Same-Threading>>
 A same-threaded system is not a pure single-threaded system, because it contains of multiple threads. But - each of the threads run like a single-threaded system.

 Same-threaded systems usually has 1 thread running per CPU in the computer. If a computer contains 4 CPUs, or a CPU with 4 cores, then it would be normal to run 4 instances of the same-threaded system (4 single-threaded systems).

 The difference between a same-threaded and a multi-threaded system is that the threads in a same-threaded system do not share state. There is no shared memory which the threads access concurrently. No concurrent data structures etc.
 
 <<Threads:>>
 
	[[1]] Creating thread by extending Thread class.
	
	[[2]] Creating thread by implementing Runnable interface.
	
  Implementing Runnable interface is preferable one. it gives more option for thread pool for execution. 
   It is easy to queue up the Runnable instances until a thread from the pool is idle.
   
   The problems arise when multiple threads access the same resources. For instance the same memory (variables, arrays, or objects), systems (databases, web services etc.) or files.
   In fact, problems only arise if one or more of the threads write to these resources. It is safe to let multiple threads read the same resources, as long as the resources do not change.
   
 <<Race Condition and Critical Section:>> The situation where two threads compete for the same resource, where the sequence in which the resource is accessed is significant, is called race conditions. 
   A code section that leads to race conditions is called a critical section.
   
   Sample code for Critical Section:

+-------------------------------+
   public class Counter 
   {
		protected long count = 0;
		public void add(long value)
		{
			this.count = this.count + value;
		}
   }
+-------------------------------+

 <<Preventing Race Conditions:>> To prevent race conditions from occurring you must make sure that the critical section is executed as an atomic instruction. 
	That means that once a single thread is executing it, no other threads can execute it until the first thread has left the critical section.  
	By using <synchronized blocks> or <synchronized methods> 	

  Sample code for Preventing Critical Section:
  
+-------------------------------+
   public class TwoSums 
   {
    private int sum1 = 0;
    private int sum2 = 0;
      public void add(int val1, int val2)
      {
        synchronized(this)
        {
            this.sum1 += val1;   
        }
        synchronized(this)
        {
            this.sum2 += val2;
        }
      }
	}
	
+-------------------------------+
	
 <Code that is safe to call by multiple threads simultaneously is called thread safe.>

 <<Local Variables:>> Local variables are stored in each thread's own stack. 
	That means that local variables are never shared between threads.
	
 <<Local Object Reference:>> All objects are stored in the shared heap.
	If an object created locally never escapes the method it was created in, it is thread safe. 
	In fact you can also pass it on to other methods and objects as long as none of these methods or objects make the passed object available to other threads.	

 <<Thread Safety and Immutability:>> Race condition <occurs> when two or more threads <writes> to shared resource[s].
	Race condition can <not occur> when two or more threads <reads> shared resource.
	We can make sure that objects shared between threads are never updated by any of the threads by making the shared objects immutable, and thereby thread safe.

 <<Java Memory Model:>>

 [[I]] Thread stack[s] and Heap memory
		
		[[1]] Each thread running in the Java virtual machine has its own thread stack.
		 
		  The thread stack contains information about what methods the thread has called to reach the current point of execution.
		  The thread stack also contains all local variables for each method being executed
		  A thread can only access it's own thread stack
	
		[[2]] The heap contains all objects created in your Java application, regardless of what thread created the object.
		 
		  This includes the object versions of the primitive types (e.g. Byte, Integer, Long etc.). 
		  It does not matter if an object was created and assigned to a local variable, or created as a member variable of another object, the object is still stored on the heap.
	
		[[3]] Static class variables are also stored on the heap along with the class definition.
		
		[]
		
	<We have to understand Java memory model as we focus on concurrent programs.>
	
	JMM, specifies
		How different threads see the values written to the shared variables by  other threads.
		How to synchronize access to shared variables when necessary.

[images/java-memory-model-2.png]

 <<Hardware memory architecture:>> Modern hardware memory architecture is somewhat different from the internal Java memory model.
 
[/images/java-memory-model-4.png]
	
 	A modern computer often has 2 or more CPUs in it. Some of these CPUs may have multiple cores too. The point is, that on a modern computer with 2 or more CPUs it is possible to have more than one thread running simultaneously. Each CPU is capable of running one thread at any given time. That means that if your Java application is multithreaded, one thread per CPU may be running simultaneously (concurrently) inside your Java application.

	Each CPU contains a set of registers which are essentially in-CPU memory. The CPU can perform operations much faster on these registers than it can perform on variables in main memory. That is because the CPU can access these registers much faster than it can access main memory.

	Each CPU may also have a CPU cache memory layer. In fact, most modern CPUs have a cache memory layer of some size. The CPU can access its cache memory much faster than main memory, but typically not as fast as it can access its internal registers. So, the CPU cache memory is somewhere in between the speed of the internal registers and main memory. Some CPUs may have multiple cache layers (Level 1 and Level 2), but this is not so important to know to understand how the Java memory model interacts with memory. What matters is to know that CPUs can have a cache memory layer of some sort.

	A computer also contains a main memory area (RAM). All CPUs can access the main memory. The main memory area is typically much bigger than the cache memories of the CPUs.

	Typically, when a CPU needs to access main memory it will read part of main memory into its CPU cache. It may even read part of the cache into its internal registers and then perform operations on it. When the CPU needs to write the result back to main memory it will flush the value from its internal register to the cache memory, and at some point flush the value back to main memory.

	The values stored in the cache memory is typically flushed back to main memory when the CPU needs to store something else in the cache memory. The CPU cache can have data written to part of its memory at a time, and flush part of its memory at a time. It does not have to read / write the full cache each time it is updated. Typically the cache is updated in smaller memory blocks called "cache lines". One or more cache lines may be read into the cache memory, and one or mor cache lines may be flushed back to main memory again.			
		
 <<Bridging The Gap Between The Java Memory Model And The Hardware Memory Architecture>>

[images/java-memory-model-5.png]

	When objects and variables can be stored in various different memory areas in the computer, certain problems may occur. The two main problems are:

	<Visibility of thread updates (writes) to shared variables.>
	<Race conditions when reading, checking and writing shared variables.>

 <<Visibility of Shared Objects>>

	If two or more threads are sharing an object, without the proper use of either volatile declarations or synchronization, updates to the shared object made by one thread may not be visible to other threads.
	The following diagram illustrates the sketched situation. One thread running on the left CPU copies the shared object into its CPU cache, and changes its count variable to 2. This change is not visible to other threads running on the right CPU, because the update to count has not been flushed back to main memory yet.

[images/java-memory-model-6.png]

	To solve this problem you can use Java's volatile keyword. The volatile keyword can make sure that a given variable is read directly from main memory, and always written back to main memory when updated.

 <<Race Conditions>>
	If two or more threads share an object, and more than one thread updates variables in that shared object, race conditions may occur.
	Imagine if thread A reads the variable count of a shared object into its CPU cache. Imagine too, that thread B does the same, but into a different CPU cache. Now thread A adds one to count, and thread B does the same. Now var1 has been incremented two times, once in each CPU cache.
	If these increments had been carried out sequentially, the variable count would be been incremented twice and had the original value + 2 written back to main memory.

[images/java-memory-model-7.png]

 To solve this problem you can use a Java synchronized block. A synchronized block guarantees that only one thread can enter a given 
 critical section of the code at any given time. Synchronized blocks also guarantee that all variables accessed inside the synchronized block will be read in from main memory,
 and when the thread exits the synchronized block, all updated variables will be flushed back to main memory again, regardless of whether the variable is declared volatile or not.

 
 <<Synchronized keyword:>> A Java synchronized block marks a method or a block of code as synchronized. Java synchronized blocks can be used to avoid race conditions.
	The synchronized keyword can be used to mark four different types of blocks. 

+--------------------+ 
1. Instance methods
2. Static methods
3. Code blocks inside instance methods
4. Code blocks inside static methods
+--------------------+ 

  <<synchronized instance method:>> we can make an instance method synchronized by declaring a method with synchronized keyword as follow. 
   this can be synchronized on <instance(object)>. Only one thread can execute inside the synchronized method at a time.
  
+-----------------+
public synchronized viod add(int value)
{
	this.count=+value;
}
+-----------------+

  <<synchronized static method:>> Synchronized static methods are synchronized on the class object of the class the synchronized static method belongs to. 
   Since only one class object exists in the Java VM per class, only one thread can execute inside a static synchronized method in the same class.
   
   If the static synchronized methods are located in different classes, then one thread can execute inside the static synchronized methods of each class. 
   One thread per class regardless of which static synchronized method it calls.
  
+-----------------+
public static synchronized viod add(int value)
{
	count=+value; 
}
+-----------------+
  
 <<Synchronized Blocks in Instance Methods:>> it is preferable to synchronize only part of a method.
  The object taken in the parentheses by the synchronized construct is called a monitor object. The code is said to be synchronized on the monitor object. 
  A synchronized instance method uses the object it belongs to as monitor object.

+-----------------+
public viod add(int value)
{
	synchronized(this)
	{
		this.count=+value;
	}
}
+-----------------+

	 <<Synchronized Blocks in static Methods:>> static synchronized block been synchronized on a different object than MyClass.class, 
	  then one thread could execute inside each method at the same time.

+-----------------+
public class MyClass 
{
	public viod add(int value)
	{
		synchronized(MyClass.class)
		{
			this.count=+value;
		}
	}
}
+-----------------+	  
 	  
 <<Java Concurrency Utilities:>> The synchronized mechanism was Java's first mechanism for synchronizing access to objects shared by multiple threads. 
  The synchronized mechanism isn't very advanced though. That is why Java 5 got a whole set of concurrency utility classes to help developers implement more fine grained concurrency control than what we get with synchronized.
 
 <<volatile Keyword:>> The Java volatile keyword is used to mark a Java variable as "being stored in main memory". 
  More precisely that means, that every read of a volatile variable will be read from the computer's main memory, and not from the CPU cache, 
  and that every write to a volatile variable will be written to main memory, and not just to the CPU cache.
  
  In a multithreaded application where the threads operate on non-volatile variables, 
  each thread may copy variables from main memory into a CPU cache while working on them, for performance reasons. 
  If your computer contains more than one CPU, each thread may run on a different CPU. That means, 
  that each thread may copy the variables into the CPU cache of different CPUs.
  
[images/java-volatile-1.png] 
 
 With non-volatile variables there are no guarantees about when the Java Virtual Machine (JVM) reads data from main memory into CPU caches, 
  or writes data from CPU caches to main memory.
 Imagine a situation in which two or more threads have access to a shared object which contains a counter variable declared like this:
  
+-------------------+
public class SharedObject 
{

    public int counter = 0;

}
+-------------------+  
  
  If the counter variable is not declared volatile there is no guarantee about when the value of the counter variable is written from the CPU cache back to main memory. This means, that the counter variable value in the CPU cache may not be the same as in main memory. 
  
[images/java-volatile-2.png]

 The problem with threads not seeing the latest value of a variable because it has not yet been written back to main memory by another thread, is called a "visibility" problem.
 
 By declaring the counter variable volatile all writes to the counter variable will be written back to main memory immediately. Also, all reads of the counter variable will be read directly from main memory.
 
+-------------------+
public class SharedObject 
{

    public volatile int counter = 0;

}
+-------------------+   
  
  <<Look at this example:>>

+-------------+
Thread A:
    sharedObject.nonVolatile = 123;
    sharedObject.counter     = sharedObject.counter + 1;

Thread B:
    int counter     = sharedObject.counter;
    int nonVolatile = sharedObject.nonVolatile;
+-------------+  
  
  Since Thread A writes the non-volatile variable sharedObject.nonVolatile before writing to the volatile sharedObject.counter, then both sharedObject.nonVolatile and sharedObject.counter are written to main memory when Thread A writes to sharedObject.counter (the volatile variable).
  
  Since Thread B starts by reading the volatile sharedObject.counter, then both the sharedObject.counter and sharedObject.nonVolatile are read from main memory into the CPU cache used by Thread B. By the time Thread B reads sharedObject.nonVolatile it will see the value written by Thread A.
  
 <<Look at this example:>>

+-----------------+
sharedObject.nonVolatile1 = 123;
sharedObject.nonVolatile2 = 456;
sharedObject.nonVolatile3 = 789;

sharedObject.volatile     = true; //a volatile variable

int someValue1 = sharedObject.nonVolatile4;
int someValue2 = sharedObject.nonVolatile5;
int someValue3 = sharedObject.nonVolatile6;
+-----------------+  

 The JVM may reorder the first 3 instructions, as long as all of them happens before the volatile write instruction (they must all be executed before the volatile write instruction).

 Similarly, the JVM may reorder the last 3 instructions as long as the volatile write instruction happens before all of them. None of the last 3 instructions can be reordered to before the volatile write instruction.

 That is basically the meaning of the Java volatile happens before guarantee.
 
 <<volatile is Not Always Enough>>
 
 Even if the volatile keyword guarantees that all reads of a volatile variable are read directly from main memory, and all writes to a volatile variable are written directly to main memory, there are still situations where it is not enough to declare a variable volatile.
 
 The situation where multiple threads are incrementing the same counter is exactly such a situation where a volatile variable is not enough.
 
 Imagine if Thread 1 reads a shared counter variable with the value 0 into its CPU cache, increment it to 1 and not write the changed value back into main memory. Thread 2 could then read the same counter variable from main memory where the value of the variable is still 0, into its own CPU cache. Thread 2 could then also increment the counter to 1, and also not write it back to main memory.
 
[images/java-volatile-3.png] 
 
 Thread 1 and Thread 2 are now practically out of sync. The real value of the shared counter variable should have been 2, but each of the threads has the value 1 for the variable in their CPU caches, and in main memory the value is still 0. It is a mess! Even if the threads eventually write their value for the shared counter variable back to main memory, the value will be wrong. 

 <<When is volatile Enough?>>
  
  if two threads are both reading and writing to a shared variable, then using the volatile keyword for that is not enough. 
  
  [[i]]  We can use synchronization which makes the reading and writing of the variable is atomic.
  
  [[ii]] We can also use one of the many atomic data types found in the java.util.concurrent package. < AutomicLong , AutomicReference...>
  
  
 <<Performance Considerations of volatile>>
 
 Reading and writing of volatile variables causes the variable to be read or written to main memory. Reading from and writing to main memory is more expensive than accessing the CPU cache. Accessing volatile variables also prevent instruction reordering which is a normal performance enhancement technique. Thus, you should only use volatile variables when you really need to enforce visibility of variables.
   
 <ThreadLocal :>>
 The ThreadLocal class in Java enables you to create variables that can only be read and written by the same thread. 
 Thus, even if two threads are executing the same code, and the code has a reference to a ThreadLocal variable, 
 then the two threads cannot see each other's ThreadLocal variables.

+---------+
 private ThreadLocal<Integer> threadLocal=new ThreadLocal<>();
 
 System.out.println(Thread.currentThread().getName());
 threadLocal.set((int)(Math.random()*100));
 
 System.out.println(Thread.currentThread().getName());
 System.out.println(threadLocal.get());
+---------+ 

 <The InheritableThreadLocal class is a subclass of ThreadLocal. Instead of each thread having its own value inside a ThreadLocal, the InheritableThreadLocal grants access to values to a thread and all child threads created by that thread.>
 
 <<Thread Signaling>> is to enable threads to send signals to each other. Additionally, thread signaling enables threads to wait for signals from other threads.
 
 Busy waiting: Signaling via shared object, one thread waits(while loop) till other thread gives signal on shared object with synchronization.
 
 Busy waiting is not a very efficient utilization of the CPU in the computer running the waiting thread, except if the average waiting time is very small.
 
 <It would be smarter if the waiting thread could somehow sleep or become inactive until it receives the signal it is waiting for.>
 
 Java has a builtin wait mechanism that enable threads to become inactive while waiting for signals. The class java.lang.Object defines three methods, wait(), notify(), and notifyAll(), to facilitate this.
 
 <Thread that calls wait() on any object becomes inactive until another thread calls notify() on that object.  the calling thread must call wait() or notify() from inside a synchronized block.>
 
 A thread cannot call wait(), notify() or notifyAll() without holding the lock on the object the method is called on. If it does, an IllegalMonitorStateException is thrown.
 Once a thread calls wait() it releases the lock it holds on the monitor object.
 
 <<Thread Deadlock>> A deadlock is when two or more threads are blocked waiting to obtain locks that some of the other threads in the deadlock are holding.
 Ex: if thread 1 locks A, and tries to lock B, and thread 2 has already locked B, and tries to lock A, a deadlock arises. Thread 1 can never get B, and thread 2 can never get A.

+-----------+
Thread 1  locks A, waits for B
Thread 2  locks B, waits for A
+-----------+

 <<Deadlock Prevention:>>
	[[1]] Lock Ordering: Deadlock occurs when multiple threads need the same locks but obtain them in different order. If you make sure that all locks are always taken in the same order by any thread, deadlocks cannot occur. 
	
	
	[[2]] Lock Timeout: Another deadlock prevention mechanism is to put a timeout on lock attempts meaning a thread trying to obtain a lock will only try for so long before giving up.
	
	[[3]] Deadlock Detection : Deadlock detection is a heavier deadlock prevention mechanism aimed at cases in which lock ordering isn't possible, and lock timeout isn't feasible.
	Every time a thread takes a lock it is noted in a data structure (map, graph etc.) of threads and locks. Additionally, whenever a thread requests a lock this is also noted in this data structure.
	
 <<Starvation:>> If a thread is not granted CPU time because other threads grab it all, it is called "starvation".
	
 The solution to starvation is called <<fairness>> - that all threads are fairly granted a chance to execute.
	
 <<Causes of Starvation:>>
	
	[[1]] Threads with high priority swallow all CPU time from threads with lower priority.(we can set the priority of threads between 1 and 10.)
	
	[[2]] Threads are blocked indefinately waiting to enter a synchronized block, because other threads are constantly allowed access before it. synchronized code block makes no guarantee about the sequence in which threads waiting to enter the synchronized block are allowed to enter.
	
	[[3]] Threads waiting on an object (called wait() on it) remain waiting indefinitely because other threads are constantly awakened instead of it.
	
 It is not possible to implement 100% fairness in java to avoid starvation.
 
+------------+
 public class Synchronizer
 {
  	public synchronized void doSynchronized()
  	{
    	//do a lot of work which takes a long time.
 	}
 }

 * If more than one thread call the doSynchronized() method, some of them will be blocked until the first thread granted access has left the method. 
   If more than one thread are blocked waiting for access there is no guarantee about which thread is granted access next.
+------------+ 
 
 <To increase the fairness, use locks instead of synchronized blocks.>

+------------+
public class Synchronizer
{
  Lock lockObj = new Lock();//it is not class, ||y implementation of Lock interface

  public void doSynchronized() throws InterruptedException
  {
    this.lockObj.lock();
    //critical section, do a lot of work which takes a long time
    this.lockObj.unlock();
  }
}
+------------+ 

 <<A simple implementation of the Lock class could look like this:>>

+-------+
public class Lock{
  private boolean isLocked      = false;
  private Thread  lockingThread = null;

  public synchronized void lock() throws InterruptedException{
    while(isLocked){
      wait();
    }
    isLocked      = true;
    lockingThread = Thread.currentThread();
  }

  public synchronized void unlock(){
    if(this.lockingThread != Thread.currentThread()){
      throw new IllegalMonitorStateException(
        "Calling thread has not locked this lock");
    }
    isLocked      = false;
    lockingThread = null;
    notify();
  }
}
+-------+
 <Notice the while(isLocked) loop, which is also called a <<spin lock">>.>
 
 <<Locks:>> A lock is a thread synchronization mechanism like synchronized blocks except locks can be more sophisticated than Java's synchronized blocks.
 
 <From Java 5 the package java.util.concurrent.locks contains several lock implementations>.
  
 <<Lock Reentrance :>> Synchronized blocks in Java are reentrant. This means, that if a Java thread enters a synchronized block of code, and thereby take the lock on the monitor object the block is synchronized on, the thread can enter other Java code blocks synchronized on the same monitor object.

+------+
public class Reentrant{
  public synchronized outer()
  {
    inner();
  }

  public synchronized inner()
  {
    //do something
  }
}
+------+ 

 Notice how both outer() and inner() are declared synchronized, which in Java is equivalent to a synchronized(this) block. 
 If a thread calls outer() there is no problem calling inner() from inside outer(), since both methods (or blocks) are synchronized on the same monitor object ("this"). 
 If a thread already holds the lock on a monitor object, it has access to all blocks synchronized on the same monitor object. This is called <<reentrance>>.
 	
 The lock implementation shown earlier is not reentrant. 
 If we rewrite the Reentrant class like below, the thread calling outer() will be blocked inside the lock.lock() in the inner() method.

+-------+ 
public class Reentrant
{

  Lock lock = new Lock();

  public outer()
  {
    lock.lock();
    inner();
    lock.unlock();
  }

  public synchronized inner()
  {
    lock.lock();
    //do something
    lock.unlock();
  }
}
+-------+ 
 
 <When guarding a critical section with a Lock, and the critical section may throw exceptions, it is important to call the unlock() method from inside a finally-clause>

+-----+
	lock.lock();
	try
	{
  		//do critical section code, which may throw exception
	} 
	finally 
	{
  		lock.unlock();
	} 
+-----+  
  
  <<Read / Write Locks>> A read / write lock is more sophisticated lock than the Lock implementations shown in the text Locks in Java.
  Locking mechanism is required while writing to shared resource not while reading shared resource. Java 5 comes with read / write lock implementations in the java.util.concurrent package. Even so, it may still be useful to know the theory behind their implementation.
 
  <<Read / Write Lock Java Implementation:>> First let's summarize the conditions for getting read and write access to the resource
  
  <Read Access:>   	If no threads are writing, and no threads have requested write access.
  
  <Write Access:>   	If no threads are reading or writing.  
  
  If a thread wants to read the resource, it is okay as long as no threads are writing to it, and no threads have requested write access to the resource. 
  By up-prioritizing write-access requests we assume that write requests are more important than read-requests.
  
  
 	  
 <<Reference Sites>>

 {{http://www.geeksforgeeks.org/jvm-works-jvm-architecture/}}
 
 {{https://www.journaldev.com}}
 
 {{http://javaconceptoftheday.com/difference-between-shallow-copy-vs-deep-copy-in-java/}}
 
 {{http://javahungry.blogspot.com/}}
 
 {https://github.com/sreedharnuli/Learnings}
 
 {http://tutorials.jenkov.com/java-util-concurrent/index.html}

